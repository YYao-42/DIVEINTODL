{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "2_2DataPreprocessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YYao-42/DIVEINTODL/blob/main/Chapter-2-Preliminaries/2_2DataPreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "2vlihbhfA3Aa"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "So far we have introduced a variety of techniques for manipulating data that are already stored in tensors.\n",
        "To apply deep learning to solving real-world problems,\n",
        "we often begin with preprocessing raw data, rather than those nicely prepared data in the tensor format.\n",
        "Among popular data analytic tools in Python, the `pandas` package is commonly used.\n",
        "Like many other extension packages in the vast ecosystem of Python,\n",
        "`pandas` can work together with tensors.\n",
        "So, we will briefly walk through steps for preprocessing raw data with `pandas`\n",
        "and converting them into the tensor format.\n",
        "We will cover more data preprocessing techniques in later chapters.\n",
        "\n",
        "## Reading the Dataset\n",
        "\n",
        "As an example,\n",
        "we begin by (**creating an artificial dataset that is stored in a\n",
        "csv (comma-separated values) file**)\n",
        "`../data/house_tiny.csv`. Data stored in other\n",
        "formats may be processed in similar ways.\n",
        "\n",
        "Below we write the dataset row by row into a csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 1,
        "tab": [
          "pytorch"
        ],
        "id": "towOFU-BA3Ag"
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
        "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
        "    f.write('2,NA,106000\\n')\n",
        "    f.write('4,NA,178100\\n')\n",
        "    f.write('NA,NA,140000\\n')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 2,
        "id": "zHqt_ATfA3Aj"
      },
      "source": [
        "To [**load the raw dataset from the created csv file**],\n",
        "we import the `pandas` package and invoke the `read_csv` function.\n",
        "This dataset has four rows and three columns, where each row describes the number of rooms (\"NumRooms\"), the alley type (\"Alley\"), and the price (\"Price\") of a house.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "ZhCthTfDA3Al",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cff470-12a8-408f-8fcd-b8976516ec65"
      },
      "source": [
        "# If pandas is not installed, just uncomment the following line:\n",
        "# !pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   NumRooms Alley   Price\n",
            "0       NaN  Pave  127500\n",
            "1       2.0   NaN  106000\n",
            "2       4.0   NaN  178100\n",
            "3       NaN   NaN  140000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "evIHFHV9A3An"
      },
      "source": [
        "## Handling Missing Data\n",
        "\n",
        "Note that \"NaN\" entries are missing values.\n",
        "To handle missing data, typical methods include *imputation* and *deletion*,\n",
        "where imputation replaces missing values with substituted ones,\n",
        "while deletion ignores missing values. Here we will consider imputation.\n",
        "\n",
        "By integer-location based indexing (`iloc`), we split `data` into `inputs` and `outputs`,\n",
        "where the former takes the first two columns while the latter only keeps the last column.\n",
        "For numerical values in `inputs` that are missing,\n",
        "we [**replace the \"NaN\" entries with the mean value of the same column.**]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UKk6aKHCDp8",
        "outputId": "41f3f786-e7eb-422c-dd93-4ca591cf4a2f"
      },
      "source": [
        "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "print(inputs)\n",
        "print(outputs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   NumRooms Alley\n",
            "0       NaN  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0   NaN\n",
            "3       NaN   NaN\n",
            "0    127500\n",
            "1    106000\n",
            "2    178100\n",
            "3    140000\n",
            "Name: Price, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "xbiZo8sUA3Ao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af515d0-ffe0-4ec2-968d-441044616054"
      },
      "source": [
        "inputs = inputs.fillna(inputs.mean())\n",
        "print(inputs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   NumRooms Alley\n",
            "0       3.0  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0   NaN\n",
            "3       3.0   NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "i7-Xoa30A3Aq"
      },
      "source": [
        "[**For categorical or discrete values in `inputs`, we consider \"NaN\" as a category.**]\n",
        "Since the \"Alley\" column only takes two types of categorical values \"Pave\" and \"NaN\",\n",
        "`pandas` can automatically convert this column to two columns \"Alley_Pave\" and \"Alley_nan\".\n",
        "A row whose alley type is \"Pave\" will set values of \"Alley_Pave\" and \"Alley_nan\" to 1 and 0.\n",
        "A row with a missing alley type will set their values to 0 and 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "n6CBy0VPA3At",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd617b3-ca9c-4e14-e62f-1678003d0ae8"
      },
      "source": [
        "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "print(inputs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   NumRooms  Alley_Pave  Alley_nan\n",
            "0       3.0           1          0\n",
            "1       2.0           0          1\n",
            "2       4.0           0          1\n",
            "3       3.0           0          1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "EQSfn8HxA3Av"
      },
      "source": [
        "## Conversion to the Tensor Format\n",
        "\n",
        "Now that [**all the entries in `inputs` and `outputs` are numerical, they can be converted to the tensor format.**]\n",
        "Once data are in this format, they can be further manipulated with those tensor functionalities that we have introduced in 2-1 Data Manipulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "3b76U5d6A3Ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8600865-20a0-4bc9-c090-cdb564c633c4"
      },
      "source": [
        "import torch\n",
        "\n",
        "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
        "X, y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3., 1., 0.],\n",
              "         [2., 0., 1.],\n",
              "         [4., 0., 1.],\n",
              "         [3., 0., 1.]], dtype=torch.float64),\n",
              " tensor([127500, 106000, 178100, 140000]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 12,
        "id": "QQuN-NQsA3Ay"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* Like many other extension packages in the vast ecosystem of Python, `pandas` can work together with tensors.\n",
        "* Imputation and deletion can be used to handle missing data.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "Create a raw dataset with more rows and columns.\n",
        "\n",
        "1. Delete the column with the most missing values.\n",
        "2. Convert the preprocessed dataset to the tensor format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 14,
        "tab": [
          "pytorch"
        ],
        "id": "pEEJsn8AA3Az"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/29)\n"
      ]
    }
  ]
}